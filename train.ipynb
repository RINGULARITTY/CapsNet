{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from capsnet.fine_tuning_helper import load_study\n",
    "\n",
    "study_name = \"main\"\n",
    "study = load_study(study_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty Study\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    display(study.best_value)\n",
    "    display(study.best_params)\n",
    "except:\n",
    "    print(\"Empty Study\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.9), please consider upgrading to the latest version (0.3.10).\n"
     ]
    }
   ],
   "source": [
    "from capsnet.dataset_helper import load_raw_datasets\n",
    "\n",
    "train_dataset_raw, val_dataset_raw, test_dataset_raw = load_raw_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RINGULARITY\\venvs\\model_train\\Lib\\site-packages\\albumentations\\core\\validation.py:58: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "100%|██████████| 1656/1656 [00:08<00:00, 187.43it/s]\n",
      "100%|██████████| 72/72 [00:00<00:00, 1763.32it/s]\n",
      "c:\\Users\\RINGULARITY\\venvs\\model_train\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "[I 2025-03-04 20:01:04,242] Trial 0 finished with value: 0.0 and parameters: {'input_size': 32, 'lr': 0.008685180967642222, 'alpha': 0.000339062627723243, 'routing_iters': 3, 'num_capsules': 58, 'capsule_dim': 5, 'primary_kernel_size': 3, 'primary_stride': 2, 'n_decoder_layers': 2, 'decoder_hidden_dim_0': 512, 'decoder_dropout_rate_0': 0.29730769834564896, 'decoder_hidden_dim_1': 128, 'decoder_dropout_rate_1': 0.4360000651975947, 'decoder_final_dropout': 0.3282070276692439}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 finished with value: 0.0 and parameters: {'input_size': 32, 'lr': 0.008685180967642222, 'alpha': 0.000339062627723243, 'routing_iters': 3, 'num_capsules': 58, 'capsule_dim': 5, 'primary_kernel_size': 3, 'primary_stride': 2, 'n_decoder_layers': 2, 'decoder_hidden_dim_0': 512, 'decoder_dropout_rate_0': 0.29730769834564896, 'decoder_hidden_dim_1': 128, 'decoder_dropout_rate_1': 0.4360000651975947, 'decoder_final_dropout': 0.3282070276692439}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-04 20:01:04,372] Trial 1 finished with value: 0.0 and parameters: {'input_size': 32, 'lr': 0.001084242268707629, 'alpha': 0.0029123752142354276, 'routing_iters': 2, 'num_capsules': 58, 'capsule_dim': 5, 'primary_kernel_size': 8, 'primary_stride': 2, 'n_decoder_layers': 2, 'decoder_hidden_dim_0': 128, 'decoder_dropout_rate_0': 0.22941637535623144, 'decoder_hidden_dim_1': 4096, 'decoder_dropout_rate_1': 0.3195730688305695, 'decoder_final_dropout': 0.37404193793413426}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 finished with value: 0.0 and parameters: {'input_size': 32, 'lr': 0.001084242268707629, 'alpha': 0.0029123752142354276, 'routing_iters': 2, 'num_capsules': 58, 'capsule_dim': 5, 'primary_kernel_size': 8, 'primary_stride': 2, 'n_decoder_layers': 2, 'decoder_hidden_dim_0': 128, 'decoder_dropout_rate_0': 0.22941637535623144, 'decoder_hidden_dim_1': 4096, 'decoder_dropout_rate_1': 0.3195730688305695, 'decoder_final_dropout': 0.37404193793413426}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RINGULARITY\\venvs\\model_train\\Lib\\site-packages\\albumentations\\core\\validation.py:58: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "100%|██████████| 1656/1656 [00:09<00:00, 179.40it/s]\n",
      "100%|██████████| 72/72 [00:00<00:00, 1416.83it/s]\n",
      "c:\\Users\\RINGULARITY\\venvs\\model_train\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "[I 2025-03-04 20:01:25,575] Trial 2 finished with value: 0.0 and parameters: {'input_size': 64, 'lr': 0.009995782111399426, 'alpha': 0.0007118822524635332, 'routing_iters': 3, 'num_capsules': 24, 'capsule_dim': 9, 'primary_kernel_size': 4, 'primary_stride': 3, 'n_decoder_layers': 2, 'decoder_hidden_dim_0': 2048, 'decoder_dropout_rate_0': 0.31595194360710377, 'decoder_hidden_dim_1': 256, 'decoder_dropout_rate_1': 0.22950985922990347, 'decoder_final_dropout': 0.25496546213719684}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 finished with value: 0.0 and parameters: {'input_size': 64, 'lr': 0.009995782111399426, 'alpha': 0.0007118822524635332, 'routing_iters': 3, 'num_capsules': 24, 'capsule_dim': 9, 'primary_kernel_size': 4, 'primary_stride': 3, 'n_decoder_layers': 2, 'decoder_hidden_dim_0': 2048, 'decoder_dropout_rate_0': 0.31595194360710377, 'decoder_hidden_dim_1': 256, 'decoder_dropout_rate_1': 0.22950985922990347, 'decoder_final_dropout': 0.25496546213719684}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RINGULARITY\\venvs\\model_train\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "[I 2025-03-04 20:02:18,338] Trial 3 finished with value: 0.9562377397160006 and parameters: {'input_size': 32, 'lr': 0.00018576669924788523, 'alpha': 0.0003950144999502601, 'routing_iters': 1, 'num_capsules': 34, 'capsule_dim': 10, 'primary_kernel_size': 3, 'primary_stride': 3, 'n_decoder_layers': 2, 'decoder_hidden_dim_0': 1024, 'decoder_dropout_rate_0': 0.23382593884745145, 'decoder_hidden_dim_1': 4096, 'decoder_dropout_rate_1': 0.4216756551354024, 'decoder_final_dropout': 0.3411668267378829}. Best is trial 3 with value: 0.9562377397160006.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 finished with value: 0.9562377397160006 and parameters: {'input_size': 32, 'lr': 0.00018576669924788523, 'alpha': 0.0003950144999502601, 'routing_iters': 1, 'num_capsules': 34, 'capsule_dim': 10, 'primary_kernel_size': 3, 'primary_stride': 3, 'n_decoder_layers': 2, 'decoder_hidden_dim_0': 1024, 'decoder_dropout_rate_0': 0.23382593884745145, 'decoder_hidden_dim_1': 4096, 'decoder_dropout_rate_1': 0.4216756551354024, 'decoder_final_dropout': 0.3411668267378829}. Best is trial 3 with value: 0.9562377397160006.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RINGULARITY\\venvs\\model_train\\Lib\\site-packages\\albumentations\\core\\validation.py:58: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "100%|██████████| 1656/1656 [00:13<00:00, 122.99it/s]\n",
      "100%|██████████| 72/72 [00:00<00:00, 778.88it/s]\n",
      "c:\\Users\\RINGULARITY\\venvs\\model_train\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "[I 2025-03-04 20:09:36,141] Trial 4 finished with value: 0.9953623188405797 and parameters: {'input_size': 128, 'lr': 0.00015591141510305244, 'alpha': 0.0005686427193811906, 'routing_iters': 5, 'num_capsules': 58, 'capsule_dim': 5, 'primary_kernel_size': 4, 'primary_stride': 2, 'n_decoder_layers': 2, 'decoder_hidden_dim_0': 512, 'decoder_dropout_rate_0': 0.35738198055304526, 'decoder_hidden_dim_1': 1024, 'decoder_dropout_rate_1': 0.42925866582391436, 'decoder_final_dropout': 0.4388723583138437}. Best is trial 4 with value: 0.9953623188405797.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 finished with value: 0.9953623188405797 and parameters: {'input_size': 128, 'lr': 0.00015591141510305244, 'alpha': 0.0005686427193811906, 'routing_iters': 5, 'num_capsules': 58, 'capsule_dim': 5, 'primary_kernel_size': 4, 'primary_stride': 2, 'n_decoder_layers': 2, 'decoder_hidden_dim_0': 512, 'decoder_dropout_rate_0': 0.35738198055304526, 'decoder_hidden_dim_1': 1024, 'decoder_dropout_rate_1': 0.42925866582391436, 'decoder_final_dropout': 0.4388723583138437}. Best is trial 4 with value: 0.9953623188405797.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RINGULARITY\\venvs\\model_train\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "[I 2025-03-04 20:15:43,732] Trial 5 finished with value: 0.9629532035329137 and parameters: {'input_size': 128, 'lr': 0.0008517352698873006, 'alpha': 0.0017037933701748238, 'routing_iters': 5, 'num_capsules': 61, 'capsule_dim': 7, 'primary_kernel_size': 8, 'primary_stride': 2, 'n_decoder_layers': 1, 'decoder_hidden_dim_0': 128, 'decoder_dropout_rate_0': 0.21907366457709768, 'decoder_final_dropout': 0.2295980471677806}. Best is trial 4 with value: 0.9953623188405797.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 finished with value: 0.9629532035329137 and parameters: {'input_size': 128, 'lr': 0.0008517352698873006, 'alpha': 0.0017037933701748238, 'routing_iters': 5, 'num_capsules': 61, 'capsule_dim': 7, 'primary_kernel_size': 8, 'primary_stride': 2, 'n_decoder_layers': 1, 'decoder_hidden_dim_0': 128, 'decoder_dropout_rate_0': 0.21907366457709768, 'decoder_final_dropout': 0.2295980471677806}. Best is trial 4 with value: 0.9953623188405797.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RINGULARITY\\venvs\\model_train\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "[I 2025-03-04 20:16:14,355] Trial 6 finished with value: 0.0 and parameters: {'input_size': 64, 'lr': 0.007118602178384287, 'alpha': 0.004473763931202239, 'routing_iters': 3, 'num_capsules': 28, 'capsule_dim': 15, 'primary_kernel_size': 3, 'primary_stride': 1, 'n_decoder_layers': 2, 'decoder_hidden_dim_0': 4096, 'decoder_dropout_rate_0': 0.3828514269945809, 'decoder_hidden_dim_1': 256, 'decoder_dropout_rate_1': 0.4022373400285234, 'decoder_final_dropout': 0.38371161674693266}. Best is trial 4 with value: 0.9953623188405797.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 finished with value: 0.0 and parameters: {'input_size': 64, 'lr': 0.007118602178384287, 'alpha': 0.004473763931202239, 'routing_iters': 3, 'num_capsules': 28, 'capsule_dim': 15, 'primary_kernel_size': 3, 'primary_stride': 1, 'n_decoder_layers': 2, 'decoder_hidden_dim_0': 4096, 'decoder_dropout_rate_0': 0.3828514269945809, 'decoder_hidden_dim_1': 256, 'decoder_dropout_rate_1': 0.4022373400285234, 'decoder_final_dropout': 0.38371161674693266}. Best is trial 4 with value: 0.9953623188405797.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RINGULARITY\\venvs\\model_train\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "[I 2025-03-04 20:16:28,731] Trial 7 finished with value: 0.0 and parameters: {'input_size': 64, 'lr': 0.006273768784604809, 'alpha': 0.0002970642110946409, 'routing_iters': 2, 'num_capsules': 27, 'capsule_dim': 16, 'primary_kernel_size': 4, 'primary_stride': 3, 'n_decoder_layers': 1, 'decoder_hidden_dim_0': 256, 'decoder_dropout_rate_0': 0.2803327175923568, 'decoder_final_dropout': 0.3100296194726768}. Best is trial 4 with value: 0.9953623188405797.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7 finished with value: 0.0 and parameters: {'input_size': 64, 'lr': 0.006273768784604809, 'alpha': 0.0002970642110946409, 'routing_iters': 2, 'num_capsules': 27, 'capsule_dim': 16, 'primary_kernel_size': 4, 'primary_stride': 3, 'n_decoder_layers': 1, 'decoder_hidden_dim_0': 256, 'decoder_dropout_rate_0': 0.2803327175923568, 'decoder_final_dropout': 0.3100296194726768}. Best is trial 4 with value: 0.9953623188405797.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RINGULARITY\\venvs\\model_train\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "[I 2025-03-04 20:17:26,667] Trial 8 finished with value: 0.0 and parameters: {'input_size': 128, 'lr': 0.007836578035052584, 'alpha': 0.00013045147892589372, 'routing_iters': 5, 'num_capsules': 56, 'capsule_dim': 8, 'primary_kernel_size': 3, 'primary_stride': 3, 'n_decoder_layers': 1, 'decoder_hidden_dim_0': 256, 'decoder_dropout_rate_0': 0.23047383434502666, 'decoder_final_dropout': 0.2591988255018764}. Best is trial 4 with value: 0.9953623188405797.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 finished with value: 0.0 and parameters: {'input_size': 128, 'lr': 0.007836578035052584, 'alpha': 0.00013045147892589372, 'routing_iters': 5, 'num_capsules': 56, 'capsule_dim': 8, 'primary_kernel_size': 3, 'primary_stride': 3, 'n_decoder_layers': 1, 'decoder_hidden_dim_0': 256, 'decoder_dropout_rate_0': 0.23047383434502666, 'decoder_final_dropout': 0.2591988255018764}. Best is trial 4 with value: 0.9953623188405797.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RINGULARITY\\venvs\\model_train\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "[I 2025-03-04 20:18:11,185] Trial 9 finished with value: 0.0 and parameters: {'input_size': 128, 'lr': 0.0029991376323844775, 'alpha': 0.0035478865822656087, 'routing_iters': 2, 'num_capsules': 41, 'capsule_dim': 16, 'primary_kernel_size': 5, 'primary_stride': 3, 'n_decoder_layers': 1, 'decoder_hidden_dim_0': 128, 'decoder_dropout_rate_0': 0.2284029804600178, 'decoder_final_dropout': 0.3128167506164513}. Best is trial 4 with value: 0.9953623188405797.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9 finished with value: 0.0 and parameters: {'input_size': 128, 'lr': 0.0029991376323844775, 'alpha': 0.0035478865822656087, 'routing_iters': 2, 'num_capsules': 41, 'capsule_dim': 16, 'primary_kernel_size': 5, 'primary_stride': 3, 'n_decoder_layers': 1, 'decoder_hidden_dim_0': 128, 'decoder_dropout_rate_0': 0.2284029804600178, 'decoder_final_dropout': 0.3128167506164513}. Best is trial 4 with value: 0.9953623188405797.\n"
     ]
    }
   ],
   "source": [
    "from capsnet.fine_tuning_helper import objective, save_study\n",
    "from capsnet.dataset_helper import CacheLoader\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cache_loader = CacheLoader(train_dataset_raw, val_dataset_raw)\n",
    "\n",
    "study.optimize(\n",
    "    lambda trial: objective(trial, 15, device, cache_loader),\n",
    "    n_trials=10\n",
    ")\n",
    "\n",
    "save_study(study_name, study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9953623188405797"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'input_size': 128,\n",
       " 'lr': 0.00015591141510305244,\n",
       " 'alpha': 0.0005686427193811906,\n",
       " 'routing_iters': 5,\n",
       " 'num_capsules': 58,\n",
       " 'capsule_dim': 5,\n",
       " 'primary_kernel_size': 4,\n",
       " 'primary_stride': 2,\n",
       " 'n_decoder_layers': 2,\n",
       " 'decoder_hidden_dim_0': 512,\n",
       " 'decoder_dropout_rate_0': 0.35738198055304526,\n",
       " 'decoder_hidden_dim_1': 1024,\n",
       " 'decoder_dropout_rate_1': 0.42925866582391436,\n",
       " 'decoder_final_dropout': 0.4388723583138437}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(study.best_value)\n",
    "display(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RINGULARITY\\venvs\\model_train\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Train Loss: 0.4394, Val Loss: 0.2882, Val F1: 66.16%\n",
      "Epoch 2/20 - Train Loss: 0.3121, Val Loss: 0.2547, Val F1: 72.09%\n",
      "Epoch 3/20 - Train Loss: 0.2996, Val Loss: 0.1947, Val F1: 83.27%\n",
      "Epoch 4/20 - Train Loss: 0.2230, Val Loss: 0.1183, Val F1: 93.11%\n",
      "Epoch 5/20 - Train Loss: 0.2027, Val Loss: 0.0983, Val F1: 93.23%\n",
      "Epoch 6/20 - Train Loss: 0.1889, Val Loss: 0.0833, Val F1: 91.59%\n",
      "Epoch 7/20 - Train Loss: 0.1625, Val Loss: 0.0671, Val F1: 93.14%\n",
      "Epoch 8/20 - Train Loss: 0.1391, Val Loss: 0.0586, Val F1: 97.20%\n",
      "Epoch 9/20 - Train Loss: 0.1226, Val Loss: 0.0497, Val F1: 94.59%\n",
      "Epoch 10/20 - Train Loss: 0.1000, Val Loss: 0.0461, Val F1: 98.61%\n",
      "Epoch 11/20 - Train Loss: 0.0862, Val Loss: 0.0436, Val F1: 98.61%\n",
      "Epoch 12/20 - Train Loss: 0.0761, Val Loss: 0.0323, Val F1: 98.61%\n",
      "Epoch 13/20 - Train Loss: 0.0637, Val Loss: 0.0583, Val F1: 90.78%\n",
      "Epoch 14/20 - Train Loss: 0.0623, Val Loss: 0.0134, Val F1: 100.00%\n",
      "Epoch 15/20 - Train Loss: 0.0561, Val Loss: 0.0179, Val F1: 100.00%\n",
      "Epoch 16/20 - Train Loss: 0.0442, Val Loss: 0.0326, Val F1: 98.61%\n",
      "Epoch 17/20 - Train Loss: 0.0527, Val Loss: 0.0718, Val F1: 85.45%\n",
      "Epoch 18/20 - Train Loss: 0.0490, Val Loss: 0.0174, Val F1: 100.00%\n",
      "Epoch 19/20 - Train Loss: 0.0306, Val Loss: 0.0042, Val F1: 100.00%\n",
      "Epoch 20/20 - Train Loss: 0.0297, Val Loss: 0.0129, Val F1: 98.61%\n",
      "Avg Top 3 F1: 100.00%\n"
     ]
    }
   ],
   "source": [
    "from capsnet.fine_tuning_helper import study_to_model_params\n",
    "from capsnet.model import CapsNet\n",
    "from capsnet.train_helper import train_capsnet\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_best_params, alpha, lr = study_to_model_params(study.best_params, conv_channels=[64, 128, 256], num_classes=6, capsule_out_dim=16)\n",
    "\n",
    "train_loader, val_loader = cache_loader.get_or_create_cache(model_best_params[\"input_size\"])\n",
    "\n",
    "best_model = CapsNet(**model_best_params).to(device)\n",
    "\n",
    "best_model_trained, top3_f1_avg = train_capsnet(best_model, train_loader, val_loader, device, epochs=20, alpha=alpha, lr=lr, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from capsnet.model import save_model\n",
    "\n",
    "save_model(best_model_trained, model_best_params, \"main\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model_train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
